{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d704f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.types import Send,interrupt, Command\n",
    "from typing import TypedDict\n",
    "import subprocess\n",
    "from openai import OpenAI\n",
    "import textwrap\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing_extensions import Annotated\n",
    "import operator\n",
    "import base64\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "memory = InMemorySaver()\n",
    "\n",
    "llm = init_chat_model(model=\"gpt-4o-mini\")\n",
    "\n",
    "class State(TypedDict):\n",
    "\n",
    "    video_file: str\n",
    "    audio_file: str\n",
    "    transcription: str\n",
    "    summaries: Annotated[list[str], operator.add]\n",
    "    thumbnail_prompts: Annotated[list[str], operator.add]\n",
    "    thumbnail_sketches: Annotated[list[str], operator.add]\n",
    "    final_summary: str\n",
    "    user_feedback: str\n",
    "    chosen_prompt: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24d1f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.resources.chat import CompletionsWithStreamingResponse\n",
    "\n",
    "\n",
    "def extract_audio(state: State):\n",
    "    output_file = state[\"video_file\"].replace(\"mp4\",\"mp3\")\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        state[\"video_file\"],\n",
    "        \"-filter:a\",\n",
    "        \"atempo=2.0\",\n",
    "        \"-y\",\n",
    "        output_file,\n",
    "    ]\n",
    "    subprocess.run(command)\n",
    "    return {\"audio_file\": output_file}\n",
    "\n",
    "def transcribe_audio(state: State):\n",
    "    client = OpenAI()\n",
    "    with open(state[\"audio_file\"], \"rb\") as audio_file:\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            response_format=\"text\",\n",
    "            file=audio_file,\n",
    "            language=\"ko\",\n",
    "            prompt=\"Jacqueline, Isabele\"\n",
    "        )\n",
    "    return {\"transcription\": transcript}\n",
    "\n",
    "def dispatch_summarizers(state: State):\n",
    "    transcription = state[\"transcription\"]\n",
    "    chunks = []\n",
    "    for i, chunk in enumerate(textwrap.wrap(transcription, 100)):\n",
    "        chunks.append({\"id\": i+1, \"chunk\": chunk})\n",
    "    return [Send(\"summarize_chunk\", chunk) for chunk in chunks]\n",
    "def summarize_chunk(chunk:str):\n",
    "    chunk_id = chunk[\"id\"]\n",
    "    chunk = chunk[\"chunk\"]\n",
    "\n",
    "    response = llm.invoke(\n",
    "        f\"\"\"Please summarize the following text:\n",
    "\n",
    "        Text: {chunk}\n",
    "        \"\"\"\n",
    "    )\n",
    "    summary = f\"[Chunk {chunk_id}] {response.content}\"\n",
    "    return {\n",
    "        \"summaries\": [summary],\n",
    "        }\n",
    "\n",
    "def mega_summary(state: State):\n",
    "    all_summaries = \"\\n\".join(state[\"summaries\"])\n",
    "    prompt = f\"\"\"\n",
    "    You are given multiple summaries of different chunks from a video transcription.\n",
    "    \n",
    "    Please create a comprehensive final summary that combines all the key points.\n",
    "\n",
    "    Individual summaries:\n",
    "\n",
    "    {all_summaries}\n",
    "    \"\"\"        \n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return {\n",
    "        \"final_summary\": response.content\n",
    "    }\n",
    "\n",
    "def dispatch_artists(state: State):\n",
    "    return [\n",
    "        Send(\"generate_thumbnails\", {\"id\": i, \"summary\": state[\"final_summary\"]}) \n",
    "        for i in [1,2,3,4,5]\n",
    "    ]\n",
    "\n",
    "def generate_thumbnails(args):\n",
    "    concept_id = args[\"id\"]\n",
    "    summary = args[\"summary\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on this video summary, create a detailed visual prompt for a YouTube thumbnail.\n",
    "\n",
    "    Create a detailed prompt for generationg a thumbnail image that would attract viewers. Include:\n",
    "    - Main visual elements\n",
    "    - Color scheme\n",
    "    - Text overlay suggestions\n",
    "    - Overall composition \n",
    "\n",
    "    Summary: {summary}\n",
    "    \"\"\" \n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    thumbnail_prompt = response.content\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    result = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=thumbnail_prompt,\n",
    "        quality=\"low\",\n",
    "        moderation=\"low\",\n",
    "        size=\"auto\",\n",
    "    )\n",
    "\n",
    "    image_bytes = base64.b64decode(result.data[0].b64_json)\n",
    "    filename = f\"thumbnail_{concept_id}.jpeg\"\n",
    "\n",
    "    with open(filename, \"wb\") as file:\n",
    "        file.write(image_bytes)\n",
    "    \n",
    "    return {\n",
    "        \"thumbnail_prompts\": [thumbnail_prompt],\n",
    "        \"thumbnail_sketches\": [filename],\n",
    "    }\n",
    "\n",
    "def human_feedback(state: State):\n",
    "    answer = interrupt({\n",
    "        \"chosen_thumbnail\": \"which thumbnail do you like the most?\",\n",
    "        \"feedback\": \"Provide any feedback or changes you'd like to make for the thumbnails\"\n",
    "    })\n",
    "\n",
    "    user_feedback = answer[\"user_feedback\"]\n",
    "    chosen_prompt = answer[\"chosen_prompt\"]\n",
    "\n",
    "    return {\n",
    "        \"user_feedback\": user_feedback,\n",
    "        \"chosen_prompt\": state[\"thumbnail_prompts\"][chosen_prompt-1],\n",
    "    }\n",
    "\n",
    "def generate_hd_thumbnail(state: State):\n",
    "    \n",
    "    chosen_prompt = state[\"chosen_prompt\"]\n",
    "    user_feedback = state[\"user_feedback\"]\n",
    "\n",
    "    prompt = prompt = f\"\"\"\n",
    "    You are a professional YouTube thumbnail designer. Take this original thumbnail prompt and create an enhanced version that incorporates the user's specific feedback.\n",
    "\n",
    "    ORIGINAL PROMPT:\n",
    "    {chosen_prompt}\n",
    "\n",
    "    USER FEEDBACK TO INCORPORATE:\n",
    "    {user_feedback}\n",
    "\n",
    "    Create an enhanced prompt that:\n",
    "        1. Maintains the core concept from the original prompt\n",
    "        2. Specifically addresses and implements the user's feedback requests\n",
    "        3. Adds professional YouTube thumbnail specifications:\n",
    "            - High contrast and bold visual elements\n",
    "            - Clear focal points that draw the eye\n",
    "            - Professional lighting and composition\n",
    "            - Optimal text placement and readability with generous padding from edges\n",
    "            - Colors that pop and grab attention\n",
    "            - Elements that work well at small thumbnail sizes\n",
    "            - IMPORTANT: Always ensure adequate white space/padding between any text and the image borders\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    final_thumbnail_prompt = response.content\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    result = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=final_thumbnail_prompt,\n",
    "        quality=\"high\",\n",
    "        moderation=\"low\",\n",
    "        size=\"auto\",\n",
    "    )\n",
    "\n",
    "    image_bytes = base64.b64decode(result.data[0].b64_json)\n",
    "\n",
    "    with open(\"thumbnail_final.jpg\", \"wb\") as file:\n",
    "        file.write(image_bytes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcfa6d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"extract_audio\", extract_audio)\n",
    "graph_builder.add_node(\"transcribe_audio\", transcribe_audio)\n",
    "graph_builder.add_node(\"summarize_chunk\", summarize_chunk)\n",
    "graph_builder.add_node(\"mega_summary\", mega_summary)\n",
    "graph_builder.add_node(\"generate_thumbnails\", generate_thumbnails)\n",
    "graph_builder.add_node(\"human_feedback\", human_feedback)\n",
    "graph_builder.add_node(\"generate_hd_thumbnail\", generate_hd_thumbnail)\n",
    "\n",
    "graph_builder.add_edge(START, \"extract_audio\")\n",
    "graph_builder.add_edge(\"extract_audio\", \"transcribe_audio\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"transcribe_audio\", dispatch_summarizers, [\"summarize_chunk\"]\n",
    ")\n",
    "graph_builder.add_edge(\"summarize_chunk\", \"mega_summary\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"mega_summary\", dispatch_artists, [\"generate_thumbnails\"]\n",
    ")\n",
    "graph_builder.add_edge(\"generate_thumbnails\", \"human_feedback\")\n",
    "graph_builder.add_edge(\"human_feedback\", \"generate_hd_thumbnail\")\n",
    "graph_builder.add_edge(\"generate_hd_thumbnail\", END)\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88358618",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\":1,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2190856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 8.0.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 17.0.0 (clang-1700.6.3.2)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/8.0.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gpl --enable-libsvtav1 --enable-libopus --enable-libx264 --enable-libmp3lame --enable-libdav1d --enable-libvpx --enable-libx265 --enable-openssl --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      60.  8.100 / 60.  8.100\n",
      "  libavcodec     62. 11.100 / 62. 11.100\n",
      "  libavformat    62.  3.100 / 62.  3.100\n",
      "  libavdevice    62.  1.100 / 62.  1.100\n",
      "  libavfilter    11.  4.100 / 11.  4.100\n",
      "  libswscale      9.  1.100 /  9.  1.100\n",
      "  libswresample   6.  1.100 /  6.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'fun.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    encoder         : Google\n",
      "  Duration: 00:02:41.49, start: 0.000000, bitrate: 683 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 640x360 [SAR 1:1 DAR 16:9], 584 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'fun.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    TSSE            : Lavf62.3.100\n",
      "  Stream #0:0(eng): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
      "    Metadata:\n",
      "      encoder         : Lavc62.11.100 libmp3lame\n",
      "      handler_name    : ISO Media file produced by Google Inc.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "[out#0/mp3 @ 0x131f0f9e0] video:0KiB audio:1262KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.026696%\n",
      "size=    1262KiB time=00:01:20.74 bitrate= 128.1kbits/s speed= 190x elapsed=0:00:00.42    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'video_file': 'fun.mp4',\n",
       " 'audio_file': 'fun.mp3',\n",
       " 'transcription': 'ìžë² ë¦¬ëŠ” ì§€ê¸ˆ ë‰´ìŠ¤ ì´¬ì˜ì— í‘¹ ë¹ ì ¸ìžˆë‹¤. ë¬´í™”ì§€ê²½ì— ë¹ ì ¸ ì±Œë¦°ì§€ ì¤‘ì¸ ìžë² ë¦¬. ë³´ê³  ìžˆìœ¼ë©´ í”¼ê°€ ê±°ê¾¸ë¡œ ì†ŸëŠ”ë‹¤. ì–´ë¨¸ë‚˜! ë‚˜ê°€ìš”! í”¼ê°€ ë‹¤ ì—‰ì·„... ìžë² ë¼! ì •ë¡€ì¹˜ëŒ€ ì§„ì§œ. ìŸ¤ ë“œë¼ì´ë°ì´ í¬ë ˆì´ì§€! ë˜ëë‚´ì•¼ì§€ ì •ë§! í•œíŽ¸, ê·¤ë½ì„ ê³¨ë¼ë‚´ëŠ” ì„¬ì„¸í•©ë‹ˆë‹¤. ì˜êµ­ì˜ ê·¸ë ˆì´ìŠ¤ë„ K-ë“œë¼ë§ˆì— í‘¹ ë¹ ì¡Œë‹¤. ì•„, ì •ë§ ì´ê±° ë‹¤ ë¹¨ë¼, ì •ë§ë¡œ! ì§„ì§œ ìŠ¤í¬ë¼ì´ìŠ¤ë‹¤, ìžë² ë¼ ì •ë§ë¡œ ì§„ì§œ! ì–´ë””ë¡ ê°€ ì „í™”ë¥¼ ê±°ëŠ” ê·¸ë ˆì´ìŠ¤. ì—¬ë³´, ì˜¤ëŠ˜ ì˜¬ ë•Œ ë§ˆì´í¬ëž‘ ê·¸ëŸ¬ë©´ ì‚¬ì™€. ë‹¹ì—°ížˆ ë ˆë“œì§€, ë‚´ê°€ í”¼ìš´ ê±°! ëª°ë¼, ì˜¤ëŠ˜ì€ ê·¸ëƒ¥ ì‹œê·¸ë„ í”¼ì›Œì•¼ê² ë‹¤, ì˜¤ëŠ˜ ì •ë§ë¡œ ì§„ì§œ! ì˜¤ëŠ˜ì€ í”¼ì›Œì•¼ ë¼! ê·¸ëƒ¥ ì‚¬ì™€! ì´ë‚ ì€ ë‹´ë°° ì—†ì´ëŠ” ë²„í‹¸ ìˆ˜ ì—†ì—ˆë‹¤. ëŠì–´ìš”! ê±°ì˜ ì˜êµ­ì¸ë‹µê²Œ ì°¨ëŠ” ìžŠì§€ ì•ŠëŠ”ë‹¤. ê·¸ëž˜, ì´ì œëŠ” ë‚˜ë„ ì–´ì©” ìˆ˜ê°€ ì—†ì–´. ê·¸ëƒ¥ ê°€! ê·¸ëž˜! ë¶ˆí˜„ë“¯ ì–´ë””ë¡ ê°€ ì „í™”ë¥¼ ê±°ëŠ” ê·¸ë ˆì´ìŠ¤. ë…¸ëž˜ë¥¼ ì´ì€ë¯¸ ì°½ë²•ìœ¼ë¡œ ë¶€ë¥¸ë‹¤. ì—¬ëŸ¬ë¶„, ëˆ„êµ¬ì„¸ìš”? ì–´, ë‚˜ì•¼ ìœ ë‚œë‹¤! ë‚˜ ê·¸ë ˆì´ìŠ¤ì•¼! ì–´, ê·¸ë ˆì´ìŠ¤! ë‚˜ ì§€ê¸ˆ ì˜¤í”¼ìŠ¤ì—ì„œ ìŠ¤í…Œì¸ë¦¬ìŠ¤ì—ì„œ ìžˆì—ˆëŠ”ë° ìœ ë‚œë‹¤! ìœ ë‚œë‹¤! ê·¸ë•Œ ì—ì–´ ì‚¥ì‚¥ê°€ ê·¸ê±° ë¬´ìŠ¨ í•˜ìˆ™ì§€ ê°™ì€ ê±° ëë‚˜ê³  ê·¸ëž¬ì—ˆì§€? ì–´, ë§žì•„ìš”, ì–¸ë‹ˆ! ìš°ë¦¬ ë§ˆì´í¬ë¥¼ ë¹„ê±°ë¦¬ íž ì´ì œ ìš°ë¦¬ ì§‘ íŒ”ê³  í•œêµ­ ê°€ì„œ ê·¸ê±°ëŠ” ì¢€ í•˜ê³  ê·¸ëž¬ê±°ë“ ? ì–´ë¨¸, ê·¸ëž˜? ì†Œë¬¸ì— ë¦°ë‚˜ ì–¸ë‹ˆê°€ ë§‰ í•œêµ­ì—ì„œ ë¸Œëžœë“œì²˜ëŸ¼ ì‚°ë‹¤ê³  ë§‰ ê·¸ëž¬ëŠ”ë°. ì´ì œ ë¦°ë‚˜ ì•„ë‹ˆê³  ì œí´ë¦°ì´ë¼ë‹ˆê¹Œ! ì´ì œ ìž˜ ìžˆìœ¼ë‹ˆê¹Œ ì´ìƒí•œ ì†Œë¦¬ ì¢€ ê·¸ë§Œí•˜ê³  ë‹¤ë…€, ë„ˆ! ì œí´ë¦° í—˜ë‹´ì— ì†ìƒí•´ì§„ ê·¸ë ˆì´ìŠ¤. ì‰¿! ê·¸ë ˆì´ìŠ¤ì•¼! ë­ì•¼? ë‹¤ì‹œ ì‹œìž‘ëœ ìœ ë‚œë‹¤ì˜ ì´ì€ë¯¸ ì°½ë²•. ì–´ë””ë¡ ê°€ ë˜ë‹¤ì‹œ ì „í™”ë¥¼ ê±°ëŠ” ê·¸ë ˆì´ìŠ¤.\\n',\n",
       " 'summaries': ['[Chunk 1] ìžë² ë¦¬ëŠ” í˜„ìž¬ ë‰´ìŠ¤ ì´¬ì˜ì— ëª°ë‘í•˜ê³  ìžˆìœ¼ë©°, ê·¸ ëª¨ìŠµì´ ë‚˜ë¥¼ ë‹¹í™©ìŠ¤ëŸ½ê²Œ í•œë‹¤. ì±Œë¦°ì§€ì— ì°¸ì—¬í•˜ê³  ìžˆëŠ” ìžë² ë¦¬ë¥¼ ë³´ê³  ìžˆìœ¼ë©´ ê°ì •ì´ ë³µìž¡í•´ì§„ë‹¤.',\n",
       "  '[Chunk 2] The text expresses excitement and enthusiasm about various topics, including the intensity of \"driving\" (possibly a reference to a game or activity) and the careful selection of tangerines. It also mentions Grace from the UK being deeply engrossed in K-dramas and emphasizes how everything seems to be happening quickly. There is a passionate tone with phrases like \"this is crazy\" and \"it\\'s really fast.\"',\n",
       "  '[Chunk 3] ê·¸ë ˆì´ìŠ¤ê°€ ì „í™”ë¡œ ë§ˆì´í¬ë¥¼ ì‚¬ë‹¬ë¼ê³  ë¶€íƒí•˜ë©°, ìžì‹ ì´ í”¼ìš´ ë ˆë“œì§€ë¥¼ ì–¸ê¸‰í•˜ê³  ì˜¤ëŠ˜ì€ ì‹œê·¸ë„ì„ í”¼ìš°ê¸°ë¡œ ê²°ì •í•˜ëŠ” ë‚´ìš©ìž…ë‹ˆë‹¤.',\n",
       "  \"[Chunk 4] The text expresses a strong craving for cigarettes, indicating that the speaker feels they cannot bear the day without smoking. They urge someone to buy cigarettes and acknowledge that they can't resist the urge any longer. Thereâ€™s also a mention of remembering to have tea, suggesting a habitual connection to British culture. Overall, the speaker feels a sense of inevitability about their desire for cigarettes.\",\n",
       "  '[Chunk 5] ê·¸ë ˆì´ìŠ¤ê°€ ì „í™”ë¥¼ ê±¸ë©° ì´ì€ë¯¸ ìŠ¤íƒ€ì¼ë¡œ ë…¸ëž˜ë¥¼ ë¶€ë¥¸ë‹¤. í†µí™” ìƒëŒ€ëŠ” ìœ ë‚œë‹¤ë¡œ, ê·¸ë ˆì´ìŠ¤ë¥¼ ì•Œì•„ë³´ê³  ëŒ€í™”ë¥¼ ì‹œìž‘í•œë‹¤. ìœ ë‚œë‹¤ëŠ” ì§€ê¸ˆ ì‚¬ë¬´ì‹¤ì—ì„œ ìŠ¤í…Œì¸ë¦¬ìŠ¤ì— ìžˆë‹¤ê³  ë§í•œë‹¤.',\n",
       "  '[Chunk 6] The text appears to be a conversation in Korean, where someone recalls a past event related to a house or lodging. One person confirms that they are selling their house and plans to go to Korea to continue with something. The tone suggests familiarity and possibly excitement about the future plans.',\n",
       "  '[Chunk 7] The text discusses a rumor about a person named ë¦°ë‚˜ (Rinna), who is now referred to as ì œí´ë¦° (Jacqueline). The speaker expresses disbelief at the rumors and requests the listener to stop spreading strange stories, implying that ì œí´ë¦° is doing well now.',\n",
       "  '[Chunk 8] ê·¸ë ˆì´ìŠ¤ëŠ” ì œí´ë¦°ì— ëŒ€í•œ í—˜ë‹´ì— ì†ìƒí•´í•˜ë©°, ìœ ë‚œë‹¤ì˜ ì´ì€ë¯¸ ì°½ë²•ì´ ë‹¤ì‹œ ì‹œìž‘ë˜ìž ë°˜ì‘ì„ ë³´ì¸ë‹¤. ê·¸ë ˆì´ìŠ¤ëŠ” ë˜ë‹¤ì‹œ ì „í™”ë¥¼ ê±¸ê³  ìžˆë‹¤.'],\n",
       " 'thumbnail_prompts': ['### YouTube Thumbnail Visual Prompt\\n\\n**Main Visual Elements:**\\n1. **Central Figure:** A vibrant and expressive illustration of Grace, with a playful and slightly distressed facial expression, holding a phone to her ear. Her hairstyle should represent a trendy vibe, possibly with stylistic elements that reflect her interest in K-dramas.\\n2. **Supporting Characters:** Include smaller depictions of Javeri, portrayed with a curious and slightly embarrassed look, and Yoonanda, who is laughing or singing in the background, evoking a sense of camaraderie. \\n3. **Background Elements:** \\n   - A blurred city skyline to symbolize the hustle and bustle related to the news and lifestyle, perhaps with a vague image of a house or apartment building, indicating the house-selling storyline.\\n   - Include tangerines artistically scattered or floating around to represent the selection process, adding a vibrant touch.\\n   - A whimsical, smoke-like effect in one corner symbolizing Graceâ€™s cravings for cigarettes intertwined with tea.\\n\\n**Color Scheme:**\\n- **Bright and Energetic:** Use a palette of warm colors such as oranges, yellows, and reds to evoke excitement and urgency. \\n- **Contrasting Elements:** Incorporate cooler tones like teal or lavender in the background and along the edges to give depth and balance, creating a visually appealing contrast with the warmer elements.\\n\\n**Text Overlay Suggestions:**\\n- Use bold, eye-catching fonts for the title overlay, such as:\\n  - â€œThis Is News?! ðŸ¤¯â€ at the top as a hook.\\n  - â€œGossip & Grapefruits!â€ at the bottom in slightly smaller text, to create intrigue.\\n- Consider adding speech bubble graphics coming from the characters, saying playful phrases like \"Did you hear about Jacqueline?\" and \"Microphone on the way!\" to provide context and enhance viewer engagement.\\n\\n**Overall Composition:**\\n- **Asymmetrical Layout:** Position Grace slightly off-center to draw focus to her while balancing the supporting characters and background elements around her.\\n- **Dynamic Angles:** Use diagonal lines in the background to create a sense of movement, enhancing the theme of urgency and excitement in the narrative.\\n- Ensure that the text is large and readable against the busy background, possibly applying a slight shadow effect for better visibility.\\n- Frame the thumbnail with a slight border to provide a polished, finished look, ensuring it stands out among other videos on YouTube.\\n\\nThis detailed visual prompt aims to create an enticing and vibrant thumbnail that captures the essence of the videoâ€™s lively discussions and emotional undertones, compelling viewers to click and engage with the content.',\n",
       "  '### YouTube Thumbnail Visual Prompt\\n\\n#### Main Visual Elements:\\n1. **Central Character Focus**: Feature a vibrant illustration of Grace, visibly animated while talking on the phone. She should have expressive facial features indicating curiosity and a mix of excitement and distress.\\n2. **Supporting Characters**: Include smaller, stylized images of Javeri with a camera (representing news coverage) and Yoonanda with a surprised expression (showing engagement in the conversation). These characters can be placed on either side of Grace.\\n3. **Symbolic Elements**:\\n   - A microphone icon next to Grace to symbolize her request for one.\\n   - A dramatic cloud or swirl of cigarette smoke above Grace to evoke her cravings.\\n   - A visual representation of tangerines, perhaps strategically placed around the bottom or corners of the thumbnail.\\n\\n#### Color Scheme:\\n- **Background**: A gradient blend of rich blue and purple to convey a sense of urgency and excitement, possibly with hints of yellow to create a vibrant and inviting atmosphere.\\n- **Text Colors**: Use bright white or electric yellow for the text overlay to ensure visibility and contrast against the background, with a black or dark shadow around the letters for added depth.\\n- **Character Colors**: Keep character clothing colorful and diverse to reflect their personalities, with Grace in red or pink hues to emphasize her vibrant nature.\\n\\n#### Text Overlay Suggestions:\\n1. **Main Title**: \"Drama & Dilemma: Graceâ€™s Rollercoaster Life!\"\\n   - Place at the top in bold, playful font.\\n2. **Subtext**: \"Secrets, Cravings, & K-Drama Fandom!\" \\n   - Positioned towards the bottom, in a slightly smaller font size. Use a different style for added flair.\\n3. **Call to Action**: \"Watch Now!\" \\n   - A playful banner that could be positioned in the lower corner, designed to pop out (perhaps a ribbon style), encouraging viewers to click.\\n\\n#### Overall Composition:\\n- **Layout**: Arrange Grace prominently in the center, with Javeri and Yoonanda slightly behind her on either side, creating a triangular composition that draws the eye inward.\\n- **Flow**: Use sweeping lines to guide the viewerâ€™s eyes around the thumbnail - from the title at the top, swirling down through the characters, and concluding at the call-to-action banner.\\n- **Background Elements**: Incorporate subtle outlines of a city skyline or blurred office elements in the background, indicating a modern, urban setting. \\n\\nThis design aims to capture the dynamic conversations and emotional complexities of the characters while inviting viewers into the thrilling nuances of Grace\\'s life and her tight-knit social circle.',\n",
       "  '**YouTube Thumbnail Visual Prompt**\\n\\n**Main Visual Elements:**\\n1. **Centerpiece Character**: A dynamic, animated illustration of *Grace*, styled with vibrant hair and an expressive face showing excitement. Sheâ€™s holding a smartphone in one hand, and the other hand is playfully gesturing as if sheâ€™s singing.\\n2. **Background Characters**: A faint, shadowy outline of two other characters, *Javeri* and *Yoonanda*, in a soft focus. Javeri could be seen with a camera, capturing news, and Yoonanda can be shown humorously mimicking Grace\\'s singing.\\n3. **Visual Accents**: Integrate elements symbolizing conversation (e.g., speech bubbles) that contain phrases like \"Did you hear?\" and \"No way!\" to hint at gossip and lively discussions.\\n4. **Tangerine Graphic**: A small, bright tangerine visually popping alongside a whimsical element that shows Graceâ€™s fascination with the fruit.\\n5. **Cigarette and Tea Options**: Stylized representations of a cigarette and a tea cup floating in the corner, hinting at Graceâ€™s struggles and cultural backgrounds.\\n\\n**Color Scheme:**\\n- **Vibrant Hues**: Utilize a bright and bold color palette, combining shades of electric blue, sunny yellow, and bold red to signify excitement and urgency. \\n- **Contrasting Elements**: Add contrasting dark tones for the background elements to enhance visibility of the foreground characters and dialogue bubbles.\\n- **Accent Colors**: Use light greens for the tangerine and soft grey to subtly represent the narratives around smoking and British culture with tea.\\n\\n**Text Overlay Suggestions:**\\n1. **Main Title**: â€œGOSSIP, AMBITION & K-DRAMAS!â€ - Use a bold, playful font at the top center of the thumbnail.\\n2. **Subheading**: â€œGraceâ€™s Wild Day!â€ - Smaller text below the main title, possibly in a whimsical font to keep it light.\\n3. **Catchphrase**: â€œWhat Are They Up To?!â€ - Positioned near Grace, in an eye-catching, slightly angled font to draw attention.\\n\\n**Overall Composition:**\\n- Position Grace prominently in the center, bathed in bright light to establish her as the focal point. \\n- Create a diagonal flow from the top left (title) to the bottom right (catchphrase) leading viewersâ€™ eyes across the thumbnail.\\n- Ensure that background characters are less pronounced but still discernible, adding depth to the situation without overshadowing Grace.\\n- Balance the arrangement with elements of gossip (speech bubbles) on one side and cultural references (cigarette, tea) on the opposite side, creating a cohesive and engaging narrative.\\n\\nThis composition will stand out in search results, showcasing the lively, complex interactions while attracting viewers curious about Graceâ€™s journey through gossip, ambition, and cultural elements.',\n",
       "  '**YouTube Thumbnail Visual Prompt:**\\n\\n**Main Visual Elements:**\\n- **Character Spotlight:**\\n  - A dynamic portrayal of two main characters: Javeri on the left, looking slightly embarrassed while filming news with a camera in hand, and Grace on the right, holding a smartphone and looking excited, perhaps mid-conversation with a surprised expression.\\n- **Thematic Symbols:**\\n  - Incorporate visual elements representing K-dramas (e.g., a popcorn bucket or a TV screen with a popular K-drama scene), a microphone (to symbolize Graceâ€™s request), and a pack of cigarettes around Grace to illustrate her habits.\\n  - A stylized illustration of tangerines scattered around, symbolizing the unique selection process mentioned.\\n  - A house silhouette or \"For Sale\" sign to represent the discussion about selling a house.\\n\\n**Color Scheme:**\\n- **Vibrant and Energetic:**\\n  - Use a bright color palette featuring oranges, yellows, and greens to create an upbeat feeling. The background could be a gradient of light blue to signify excitement and urgency.\\n- **Contrast:**\\n  - Ensure Javeriâ€™s and Graceâ€™s outfits stand out, perhaps using darker hues or contrasting colors to emphasize their emotions (e.g., deep navy for Javeri and a bright red or pink for Grace).\\n\\n**Text Overlay Suggestions:**\\n- Bold phrases using eye-catching fonts:\\n  - \"Gossip Gone Wild!\" at the top in an energetic font.\\n  - \"K-Drama & Cravings!\" in a slightly smaller, playful font at the bottom.\\n  - \"Will They Make It?\" in a burst bubble effect to evoke curiosity and invite clicks.\\n\\n**Overall Composition:**\\n- Split the thumbnail diagonally to separate the two main characters. Place Javeri on the left with a camera, showcasing his emotion, while Grace is on the right, emphasizing her excitement, perhaps with her hand raised as if she\\'s talking on the phone.\\n- Overlay elements such as tangerines and the microphone subtly blend into the background to prevent clutter, while shining visuals of gossip (words or phrases) could zigzag through the center of the composition.\\n- Ensure the text is legible, with a slight drop shadow for clarity against the background. The overall layout should be balanced, drawing the viewer\\'s eye across the thumbnail while maintaining focus on the characters and key elements of the discussion. \\n\\nThis design should create an enticing visual summary that accurately reflects the video\\'s core themes, encouraging viewers to click and engage with the content.',\n",
       "  \"**YouTube Thumbnail Visual Prompt**\\n\\n- **Main Visual Elements**:\\n  - **Central Character**: Feature a vibrant portrayal of Grace, a young woman with a playful, expressive face. She should be holding a smartphone, looking animated as if she's in mid-conversation. Surround her with a soft glow to highlight her dynamic presence.\\n  - **Supporting Characters**: Include small, circular inset images of Javeri and Yoonanda in the background, displaying their reactionsâ€”Javeri looking slightly embarrassed and Yoonanda appearing amused or surprised.\\n  - **Visual Icons**: Add icons representing key themesâ€”like a news camera, a microphone, a cigarette, and a stylized houseâ€”with small arrows or lines connecting them to Grace, indicating her multitasking nature and the interconnectedness of the topics.\\n\\n- **Color Scheme**:\\n  - Use a bold and vibrant color palette: rich reds and deep blues for excitement and urgency, contrasted with pastel tones (light pinks and yellows) for a playful, conversational vibe. The background could be a gradient of dark to light, suggesting an evening setting transitioning into night, symbolizing rapid change.\\n\\n- **Text Overlay Suggestions**:\\n  - Main Title: â€œGossip, Cigarettes & K-Dramas!â€ in a fun, bold font that captures attention (consider a mix of playful script and thick sans-serif).\\n  - Subtext: â€œJoin the Chaos!â€ in smaller text, perhaps in a bright yellow or white for contrast.\\n  - Include a callout bubble or banner at the bottom that says â€œDonâ€™t Miss the Rumors!â€ in a splashy, eye-catching style.\\n\\n- **Overall Composition**:\\n  - Position Grace in the center-right of the thumbnail for strong impact, with her expression drawing in viewers. Space out the supporting characters in the background, ensuring they donâ€™t overshadow Grace but enhance the storyline.\\n  - Place the main title at the top of the thumbnail, possibly curving it over Graceâ€™s head or in an arc above the characters. The subtext should be situated at the bottom, providing a balanced frame.\\n  - The visual icons can be interspersed lightly around the characters, like additional elements contributing to the scene, helping to emphasize the chaotic yet lively atmosphere of gossiping and personal dilemmas.\\n\\n*The end result should be a colorful, dynamic image that conveys excitement and engagement, inviting viewers to immerse themselves in the unfolding drama and humor featured in the video.*\"],\n",
       " 'thumbnail_sketches': ['thumbnail_1.jpeg',\n",
       "  'thumbnail_2.jpeg',\n",
       "  'thumbnail_3.jpeg',\n",
       "  'thumbnail_4.jpeg',\n",
       "  'thumbnail_5.jpeg'],\n",
       " 'final_summary': 'In the video transcription, several key points emerge from different discussions and interactions among the characters involved:\\n\\n1. **Javeri\\'s Engagement with News**: Javeri is currently focused on filming news, which evokes a sense of embarrassment and complex emotions in those observing him.\\n\\n2. **Excitement and Rapid Developments**: There is a palpable enthusiasm about various topics, including a high-energy activity referred to as \"driving,\" and an interesting selection process of tangerines. Grace from the UK is particularly engrossed in K-dramas, and the overall atmosphere reflects a sense of urgency and rapidity, illustrated by expressions of amazement.\\n\\n3. **Grace\\'s Requests and Decisions**: Grace is on the phone requesting someone to buy her a microphone and mentions her choice of smoking a \\'redji\\' and deciding to smoke a \\'signal\\' that day. This highlights her current state and personal choices.\\n\\n4. **Cigarette Cravings**: The narrative conveys a strong craving for cigarettes, with the speaker resigned to the idea that they cannot get through the day without smoking. This sense of inevitability underscores a habitual connection, also referring to tea, linking back to British cultural practices.\\n\\n5. **Telephone Call with Yoonanda**: In a playful moment, Grace sings in the style of a singer named Lee Eun-mi while on the phone with Yoonanda. Yoonanda responds, mentioning they are currently in their office.\\n\\n6. **Discussion of Selling a House**: A conversation ensues where one person reminisces about a past experience related to lodging, confirming that they are selling a house to head to Korea, reflecting a sense of excitement about future plans.\\n\\n7. **Rumors About Rinna/Jacqueline**: Thereâ€™s a rumor regarding Rinna, now referred to as Jacqueline. The speaker expresses disbelief at these rumors and pleads with the listener to refrain from spreading strange stories, acknowledging that Jacqueline is actually doing well.\\n\\n8. **Grace\\'s Reaction to Gossip**: Grace shows distress over the gossip concerning Jacqueline, and reacts as Yoonanda resumes the singing style of Lee Eun-mi. Grace is actively engaged in making another phone call, indicating her dynamic presence in the conversations.\\n\\nOverall, the interactions showcase a blend of personal struggles, cultural references, excitement, and interpersonal connections among the characters as they navigate their lives and relationships.',\n",
       " '__interrupt__': [Interrupt(value={'chosen_thumbnail': 'which thumbnail do you like the most?', 'feedback': \"Provide any feedback or changes you'd like to make for the thumbnails\"}, id='b049e6f50931eb174971b1fd9125daf8')]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(\n",
    "    {\"video_file\": \"fun.mp4\"},\n",
    "    config=config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0faed55b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m response = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muser_feedback\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mMake sure the fellas are smiling, the lady looks Korean, give it a photo realistic, 3d style.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mchosen_prompt\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m2\u001b[39m,\n\u001b[32m      4\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 163\u001b[39m, in \u001b[36mgenerate_hd_thumbnail\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    159\u001b[39m final_thumbnail_prompt = response.content\n\u001b[32m    161\u001b[39m client = OpenAI()\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m result = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-image-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinal_thumbnail_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhigh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmoderation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m image_bytes = base64.b64decode(result.data[\u001b[32m0\u001b[39m].b64_json)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mthumbnail_final.jpg\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/openai/resources/images.py:885\u001b[39m, in \u001b[36mImages.generate\u001b[39m\u001b[34m(self, prompt, background, model, moderation, n, output_compression, output_format, partial_images, quality, response_format, size, stream, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    857\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate\u001b[39m(\n\u001b[32m    859\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    883\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    884\u001b[39m ) -> ImagesResponse | Stream[ImageGenStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/images/generations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmoderation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoderation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_compression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpartial_images\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquality\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstyle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageGenerateParamsStreaming\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageGenerateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mImagesResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageGenStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/openai/_base_client.py:1297\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1288\u001b[39m     warnings.warn(\n\u001b[32m   1289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing raw bytes as `body` is deprecated and will be removed in a future version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1290\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease pass raw bytes via the `content` parameter instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1291\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   1292\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1293\u001b[39m     )\n\u001b[32m   1294\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1295\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, content=content, files=to_httpx_files(files), **options\n\u001b[32m   1296\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/openai/_base_client.py:1005\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1003\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1005\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1011\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/AiAgents/YOUTUBE-THUMBNAIL-MAKER-AGENT/.venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.11/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "response = {\n",
    "    \"user_feedback\": \"Make sure the fellas are smiling, the lady looks Korean, give it a photo realistic, 3d style.\",\n",
    "    \"chosen_prompt\": 2,\n",
    "}\n",
    "\n",
    "graph.invoke(\n",
    "    Command(resume=response),\n",
    "    config=config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
